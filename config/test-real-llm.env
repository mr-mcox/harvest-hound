# Real LLM Service Configuration for Testing
# This configuration enables testing with actual LLM services

# Application Environment
NODE_ENV=test
PYTHON_ENV=test

# Database Configuration
DATABASE_URL=sqlite:///./test_real_llm.db

# LLM Service Configuration
# Set to true to enable actual LLM calls during testing
USE_REAL_LLM=true

# BAML Configuration
# Configure your actual LLM service provider here
BAML_API_KEY=your_api_key_here
BAML_MODEL=gpt-4o-mini
BAML_TIMEOUT=30000
BAML_MAX_RETRIES=3

# Alternative LLM Providers (uncomment as needed)
# OPENAI_API_KEY=your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here
# GOOGLE_API_KEY=your_google_key_here

# Performance Settings
# Increase timeouts for real LLM calls
HTTP_TIMEOUT=60000
LLM_TIMEOUT=45000

# Logging Configuration
LOG_LEVEL=info
LOG_LLM_REQUESTS=true
LOG_LLM_RESPONSES=true

# Test-specific Settings
TEST_STORE_PREFIX=test_real_llm_
TEST_CLEANUP_AFTER_RUN=true

# Rate Limiting (to avoid hitting API limits)
LLM_RATE_LIMIT_REQUESTS_PER_MINUTE=10
LLM_RATE_LIMIT_TOKENS_PER_MINUTE=5000

# Cost Control
MAX_DAILY_LLM_COST=5.00
ALERT_COST_THRESHOLD=3.00

# Monitoring
ENABLE_PERFORMANCE_MONITORING=true
CAPTURE_LLM_METRICS=true

# Warning: Real LLM testing incurs costs
# Monitor usage and set appropriate limits
COST_TRACKING_ENABLED=true